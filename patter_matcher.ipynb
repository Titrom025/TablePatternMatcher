{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d868f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968a26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOD_MATCH_PERCENT = 0.15\n",
    "RESULTS_DIR = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec4852d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_files(dirpath, ext):\n",
    "    files = [s for s in os.listdir(dirpath)\n",
    "         if os.path.isfile(os.path.join(dirpath, s)) and os.path.splitext(s)[1] == ext]\n",
    "    files.sort()\n",
    "    return files\n",
    "\n",
    "def createDir(dirpath, ext):\n",
    "    if os.path.exists(dirpath):\n",
    "        for file in get_files(dirpath, ext):\n",
    "            os.remove(os.path.join(dirpath, file))\n",
    "    else:\n",
    "        os.mkdir(dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09f2d5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def align(table_file, pattern_im, table_im): #21/45\n",
    "    sift = cv2.xfeatures2d.SIFT_create() \n",
    "    kp_image, desc_image =sift.detectAndCompute(pattern_im, None) \n",
    "    index_params = dict(algorithm = 1, trees = 5) \n",
    "    search_params = dict() \n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params) \n",
    "\n",
    "    frame = table_im\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "    kp_grayframe, desc_grayframe = sift.detectAndCompute(grayframe, None) \n",
    "\n",
    "    matches= flann.knnMatch(desc_image, desc_grayframe, k=2) \n",
    "\n",
    "    good_points=[] \n",
    "\n",
    "    for m, n in matches: \n",
    "\n",
    "        if(m.distance < 0.6*n.distance): \n",
    "            good_points.append(m) \n",
    "            \n",
    "    query_pts = np.float32([kp_image[m.queryIdx] \n",
    "                .pt for m in good_points]).reshape(-1, 1, 2) \n",
    " \n",
    "    train_pts = np.float32([kp_grayframe[m.trainIdx] \n",
    "                    .pt for m in good_points]).reshape(-1, 1, 2) \n",
    "\n",
    "    matrix, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0) \n",
    "\n",
    "    matches_mask = mask.ravel().tolist() \n",
    "    \n",
    "    height, width, channels = table_im.shape\n",
    "    res = cv2.warpPerspective(frame, matrix, (width, height))\n",
    "    \n",
    "    pts = np.array([[13,400],[1330,606]], np.float32)\n",
    "    pts = np.array([pts], np.float32)\n",
    "\n",
    "    dst = cv2.perspectiveTransform(pts, matrix)\n",
    "    \n",
    "    res = cv2.rectangle(res, (int(dst[0][0][0]), int(dst[0][0][1])), \n",
    "                             (int(dst[0][1][0]), int(dst[0][1][1])), (0, 0, 255), 2)\n",
    "#     cv2.imwrite(RESULTS_DIR + table_file + \"_borders.jpg\", table_im)\n",
    "    \n",
    "    cv2.imwrite(RESULTS_DIR + table_file + \"_align.jpg\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28289c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def alignImages(table_file, pattern_im, table_im): #37/48\n",
    "    BLACK_LIMIT = 200\n",
    "    \n",
    "    im1Gray = cv2.cvtColor(pattern_im, cv2.COLOR_BGR2GRAY)\n",
    "    im2Gray = cv2.cvtColor(table_im, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    orb = cv2.ORB_create(500, scaleFactor = 1.2, nlevels = 8,\n",
    "                        edgeThreshold = 5, firstLevel = 0, WTA_K = 4, \n",
    "                        patchSize = 95, fastThreshold = 90)\n",
    "\n",
    "\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "\n",
    "    newkeypoints1 = []\n",
    "    newdescriptors1 = []\n",
    "    newkeypoints2 = []\n",
    "    newdescriptors2 = []\n",
    "    for index_obj in range(len(keypoints1)):\n",
    "        point = keypoints1[index_obj]\n",
    "        minDist = MIN_DIST\n",
    "        minindex = 0\n",
    "        for index_scene in range(len(keypoints2)):\n",
    "            neighbour = keypoints2[index_scene]\n",
    "            \n",
    "            if ((neighbour.pt[0] - point.pt[0])**2 + (neighbour.pt[1] - point.pt[1])**2) < minDist:\n",
    "                minDist = ((neighbour.pt[0] - point.pt[0])**2 + (neighbour.pt[1] - point.pt[1])**2)\n",
    "                minindex = index_scene\n",
    "                \n",
    "        if minDist < MIN_DIST:\n",
    "            newkeypoints1.append(point)\n",
    "            newdescriptors1.append(descriptors1[index_obj])\n",
    "            newkeypoints2.append(keypoints2[minindex])\n",
    "            newdescriptors2.append(descriptors2[minindex])\n",
    "        \n",
    "    keypoints1 = newkeypoints1\n",
    "    descriptors1 = np.array(newdescriptors1)\n",
    "    keypoints2 = newkeypoints2\n",
    "    descriptors2 = np.array(newdescriptors2)\n",
    "    \n",
    "    print(len(keypoints1), len(newkeypoints2), len(descriptors1), len(newdescriptors2))\n",
    "    \n",
    "    if len(keypoints1) < 4:\n",
    "        print(\"Not enough elements\")\n",
    "        cv2.imwrite(RESULTS_DIR + table_file + \"_borders.jpg\", table_im)\n",
    "        return\n",
    "    \n",
    "    # Match features.\n",
    "#     matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "    matcher = cv2.BFMatcher()\n",
    "    matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "    # Sort matches by score\n",
    "    matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "    # Remove not so good matches\n",
    "#     numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "#     matches = matches[:numGoodMatches]\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "\n",
    "    filter_matches = []\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = keypoints1[i].pt\n",
    "        points2[i, :] = keypoints2[i].pt\n",
    "#         points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "#         points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "        \n",
    "    # Draw top matches\n",
    "#     imMatches = cv2.drawMatches(pattern_im, keypoints1, table_im, keypoints2, matches, None)\n",
    "    imMatches = cv2.drawMatches(im1Gray, keypoints1, im2Gray, keypoints2, matches, None)\n",
    "    cv2.imwrite(RESULTS_DIR + table_file + \"_matches.jpg\", imMatches)\n",
    "    \n",
    "    # Find homography\n",
    "    h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    if h is None:\n",
    "        print(\"None matrix\")\n",
    "        cv2.imwrite(RESULTS_DIR + table_file + \"_borders.jpg\", table_im)\n",
    "        return\n",
    "    \n",
    "    height, width, channels = table_im.shape\n",
    "    im1Reg = cv2.warpPerspective(pattern_im, h, (width, height))\n",
    "    \n",
    "    \n",
    "    pts = np.array([[13,400],[1330,606]], np.float32)\n",
    "    pts = np.array([pts], np.float32)\n",
    "    \n",
    "#     pattern_im = cv2.rectangle(pattern_im, (int(pts[0][0][0]), int(pts[0][0][1])), \n",
    "#                                (int(pts[0][1][0]), int(pts[0][1][1])), (0, 0, 255), 2)\n",
    "#     cv2.imwrite(RESULTS_DIR + \"pattern_border.jpg\", pattern_im)\n",
    "\n",
    "    dst = cv2.perspectiveTransform(pts, h)\n",
    "    \n",
    "    table_im = cv2.rectangle(table_im, (int(dst[0][0][0]), int(dst[0][0][1])), \n",
    "                             (int(dst[0][1][0]), int(dst[0][1][1])), (0, 0, 255), 2)\n",
    "    cv2.imwrite(RESULTS_DIR + table_file + \"_borders.jpg\", table_im)\n",
    "    \n",
    "#     cv2.imwrite(RESULTS_DIR + table_file + \"_aligned.jpg\", im1Reg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5cde577",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match(table_file, pattern_im, table_im): \n",
    "    BLACK_LIMIT = 170\n",
    "    \n",
    "    \n",
    "#     im1Gray = cv2.cvtColor(pattern_im, cv2.COLOR_BGR2GRAY)\n",
    "#     im2Gray = cv2.cvtColor(table_im, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     im1Gray[im1Gray < BLACK_LIMIT] = 0\n",
    "#     im1Gray[im1Gray > BLACK_LIMIT] = 255\n",
    "\n",
    "#     im2Gray[im2Gray < BLACK_LIMIT] = 0\n",
    "#     im2Gray[im2Gray > BLACK_LIMIT] = 255\n",
    "    \n",
    "    img_object = pattern_im\n",
    "    img_scene = table_im\n",
    "\n",
    "    #-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors\n",
    "\n",
    "#     detector = cv2.SIFT_create(minHessian)\n",
    "    detector = cv2.SIFT_create(nfeatures=200, nOctaveLayers=5, \n",
    "                               contrastThreshold=0.04, edgeThreshold=10, \n",
    "                               sigma=1.6)\n",
    "    keypoints_obj, descriptors_obj = detector.detectAndCompute(img_object, None)\n",
    "    keypoints_scene, descriptors_scene = detector.detectAndCompute(img_scene, None)\n",
    "    \n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "    knn_matches = matcher.knnMatch(descriptors_obj, descriptors_scene, 2)\n",
    "\n",
    "    ratio_thresh = RATION_TRESH\n",
    "    good_matches = []\n",
    "    for m,n in knn_matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good_matches.append(m)\n",
    "            \n",
    "    print(len(good_matches))\n",
    "\n",
    "    img_matches = np.empty((max(img_object.shape[0], img_scene.shape[0]), img_object.shape[1]+img_scene.shape[1], 3), dtype=np.uint8)\n",
    "    cv2.drawMatches(img_object, keypoints_obj, img_scene, keypoints_scene, good_matches, img_matches)\n",
    "#     cv2.drawMatches(img_object, keypoints_obj, img_scene, keypoints_scene, good_matches, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    #-- Localize the object\n",
    "    obj = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "    scene = np.empty((len(good_matches),2), dtype=np.float32)\n",
    "    for i in range(len(good_matches)):\n",
    "        #-- Get the keypoints from the good matches\n",
    "        obj[i,0] = keypoints_obj[good_matches[i].queryIdx].pt[0]\n",
    "        obj[i,1] = keypoints_obj[good_matches[i].queryIdx].pt[1]\n",
    "        scene[i,0] = keypoints_scene[good_matches[i].trainIdx].pt[0]\n",
    "        scene[i,1] = keypoints_scene[good_matches[i].trainIdx].pt[1]\n",
    "        \n",
    "    if len(good_matches) < 4:\n",
    "        print(\"    Lack of matches\")\n",
    "    else:\n",
    "        H, _ =  cv2.findHomography(obj, scene, cv2.RANSAC, 3.0)\n",
    "        \n",
    "        if H is None:\n",
    "            print(\"    None matrix\")\n",
    "        else:\n",
    "            #-- Get the corners from the image_1 ( the object to be \"detected\" )\n",
    "            obj_corners = np.empty((4,1,2), dtype=np.float32)\n",
    "            obj_corners[0,0,0] = 0\n",
    "            obj_corners[0,0,1] = 0\n",
    "            obj_corners[1,0,0] = img_object.shape[1]\n",
    "            obj_corners[1,0,1] = 0\n",
    "            obj_corners[2,0,0] = img_object.shape[1]\n",
    "            obj_corners[2,0,1] = img_object.shape[0]\n",
    "            obj_corners[3,0,0] = 0\n",
    "            obj_corners[3,0,1] = img_object.shape[0]\n",
    "            scene_corners = cv2.perspectiveTransform(obj_corners, H)\n",
    "            \n",
    "            pts = np.array([[13,400],[1330,606]], np.float32)\n",
    "            pts = np.array([pts], np.float32)\n",
    "\n",
    "            dst = cv2.perspectiveTransform(pts, H)\n",
    "\n",
    "            img_matches = cv2.rectangle(img_matches, \n",
    "                                        (int(dst[0][0][0]) + img_object.shape[1], int(dst[0][0][1])), \n",
    "                                        (int(dst[0][1][0]) + img_object.shape[1], int(dst[0][1][1])), \n",
    "                                        (0, 0, 255), 2)\n",
    "\n",
    "            cv2.line(img_matches, (int(scene_corners[0,0,0] + img_object.shape[1]), int(scene_corners[0,0,1])),\\\n",
    "                (int(scene_corners[1,0,0] + img_object.shape[1]), int(scene_corners[1,0,1])), (0,255,0), 4)\n",
    "            cv2.line(img_matches, (int(scene_corners[1,0,0] + img_object.shape[1]), int(scene_corners[1,0,1])),\\\n",
    "                (int(scene_corners[2,0,0] + img_object.shape[1]), int(scene_corners[2,0,1])), (0,255,0), 4)\n",
    "            cv2.line(img_matches, (int(scene_corners[2,0,0] + img_object.shape[1]), int(scene_corners[2,0,1])),\\\n",
    "                (int(scene_corners[3,0,0] + img_object.shape[1]), int(scene_corners[3,0,1])), (0,255,0), 4)\n",
    "            cv2.line(img_matches, (int(scene_corners[3,0,0] + img_object.shape[1]), int(scene_corners[3,0,1])),\\\n",
    "                (int(scene_corners[0,0,0] + img_object.shape[1]), int(scene_corners[0,0,1])), (0,255,0), 4)\n",
    "    \n",
    "    cv2.imwrite(RESULTS_DIR + table_file + \"_matches.jpg\", img_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38f2fecc-ce07-4c81-8b94-852bcfc5666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def largestTrianglePointsIdxs(points):\n",
    "    area = 0\n",
    "    pointsIdxs = [0,0,0]\n",
    "    if len(points) < 3:\n",
    "        return None\n",
    "    \n",
    "    for i in range(len(points)-2):\n",
    "        x1,y1 = points[i]\n",
    "        for j in range(i+1,len(points)-1):\n",
    "            x2,y2 = points[j]\n",
    "            for k in range(j+1,len(points)):\n",
    "                x3,y3 = points[k]\n",
    "                if abs(0.5*(x1*(y2-y3)+x2*(y3-y1)+x3*(y1-y2))) > area :\n",
    "                    area = abs(0.5*(x1*(y2-y3)+x2*(y3-y1)+x3*(y1-y2)))\n",
    "                    pointsIdxs = [i,j,k]\n",
    "\n",
    "    return pointsIdxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fa034776-4d39-4455-81f6-50167c6b1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignImages(table_file, pattern_im, table_im, regions_pattern, regions_table):\n",
    "    keypoints_pattern = regions_pattern\n",
    "    keypoints_table = regions_table\n",
    "    \n",
    "    print(len(keypoints_pattern), len(keypoints_table))\n",
    "    if len(keypoints_pattern) < 3 or len(keypoints_table) < 3:\n",
    "        print(\"Not enough elements\")\n",
    "        cv2.imwrite(RESULTS_DIR + table_file + \"_borders.jpg\", table_im)\n",
    "        return\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    new_matches = []\n",
    "    for pIndex, keypoint_pattern in enumerate(keypoints_pattern):\n",
    "        minDist = 35\n",
    "        pairIndex = 0\n",
    "        for tIndex, keypoint_table in enumerate(keypoints_table):\n",
    "            if math.sqrt((keypoint_pattern[0] - keypoint_table[0])**2 + (keypoint_pattern[1] - keypoint_table[1])**2) < minDist:\n",
    "                if keypoint_table not in pts2:\n",
    "                    pairIndex = tIndex\n",
    "                    minDist = math.sqrt((keypoint_pattern[0] - keypoint_table[0])**2 \n",
    "                                      + (keypoint_pattern[1] - keypoint_table[1])**2)\n",
    "        if minDist < 35:\n",
    "            keypoint_table = keypoints_table[pairIndex]\n",
    "            dmatch = cv2.DMatch(pIndex, pairIndex, 100)\n",
    "            cv2.circle(table_im, (int(keypoint_pattern[0]), int(keypoint_pattern[1])), \n",
    "                       radius=35, color=(255, 0, 0), thickness=2)\n",
    "            new_matches.append(dmatch)\n",
    "            pts1.append(keypoint_pattern)\n",
    "            pts2.append(keypoint_table)\n",
    "        \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    \n",
    "    for point in keypoints_pattern:\n",
    "        cv2.circle(pattern_im, (int(point[0]), int(point[1])), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "        \n",
    "    for point in pts1.astype(int):\n",
    "        cv2.circle(pattern_im, (int(point[0]), int(point[1])), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "        \n",
    "    \n",
    "    for point in keypoints_pattern:\n",
    "        cv2.circle(table_im, (int(point[0]), int(point[1])), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "        \n",
    "    for point in keypoints_table:\n",
    "        cv2.circle(table_im, (int(point[0]), int(point[1])), radius=10, color=(0, 0, 255), thickness=-1)\n",
    "        \n",
    "    for point in pts2.astype(int):\n",
    "        cv2.circle(table_im, (int(point[0]), int(point[1])), radius=10, color=(0, 255, 0), thickness=-1)\n",
    "        \n",
    "    kp_pattern = [cv2.KeyPoint(point[0], point[1], 5) for point in keypoints_pattern]\n",
    "    kp_table = [cv2.KeyPoint(point[0], point[1], 5) for point in keypoints_table]\n",
    "    \n",
    "    imMatches = cv2.drawMatches(pattern_im, kp_pattern, table_im, kp_table, new_matches, None)          \n",
    "#     cv2.imwrite(RESULTS_DIR + table_file + \"_matches.jpg\", imMatches)\n",
    "    \n",
    "    print(\"Matches:\", len(new_matches))\n",
    "    if len(new_matches) < 3:\n",
    "        print(\"Lack of matches\")\n",
    "        cv2.imwrite(RESULTS_DIR + table_file + \"_borders.jpg\", table_im)\n",
    "        return \n",
    "\n",
    "    pointsIndexes = largestTrianglePointsIdxs(pts1)\n",
    "    \n",
    "    pts1 = np.float32([pts1[pointsIndexes[0]], pts1[pointsIndexes[1]], pts1[pointsIndexes[2]]])\n",
    "    pts2 = np.float32([pts2[pointsIndexes[0]], pts2[pointsIndexes[1]], pts2[pointsIndexes[2]]])\n",
    "    \n",
    "    matrixAff = cv2.getAffineTransform(pts1, pts2) \n",
    "    \n",
    "    pts = np.array([[13,400],[1330,606]], np.float32)\n",
    "    pts = np.array([pts], np.float32)\n",
    "    \n",
    "    dst = cv2.transform(pts, matrixAff).astype(int)\n",
    "    \n",
    "    pts_for_affin =  np.array([pts1], np.float32)\n",
    "    dst_points = cv2.transform(pts_for_affin, matrixAff).astype(int)\n",
    "                \n",
    "    if abs(len(keypoints_pattern) - len(keypoints_table)) < len(keypoints_pattern) * 0.15 \\\n",
    "        and len(new_matches) > len(keypoints_table) * 0.85:\n",
    "        \n",
    "        for point in dst_points[0]:\n",
    "            cv2.circle(table_im, (int(point[0]), int(point[1])), radius=10, color=(255, 0, 255), thickness=-1)\n",
    "        \n",
    "        cv2.line(table_im, dst_points[0][0], dst_points[0][1], \n",
    "                 (255, 0, 255), 3, cv2.LINE_AA)\n",
    "        cv2.line(table_im, dst_points[0][1], dst_points[0][2], \n",
    "                 (255, 0, 255), 3, cv2.LINE_AA)\n",
    "        cv2.line(table_im, dst_points[0][2], dst_points[0][0], \n",
    "                 (255, 0, 255), 3, cv2.LINE_AA)\n",
    "\n",
    "        table_im = cv2.rectangle(table_im, pts[0][0].astype(int), \n",
    "                                 pts[0][1].astype(int), (0, 0, 255), 5)\n",
    "        table_im = cv2.rectangle(table_im, dst[0][0], dst[0][1], (0, 255, 0), 5)\n",
    "        \n",
    "        print(\"Correct pattern!\")\n",
    "    else:\n",
    "        print(\"Another pattern!\")\n",
    "\n",
    "    cv2.imwrite(RESULTS_DIR + table_file + \"_borders.jpg\", table_im)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2f375a8-c082-4d5a-bf21-b0ecb0c150c0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rotateIMG(image):\n",
    "#     image = cv2.imread(jpgPath)\n",
    "    midImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    BLACK_LIMIT = 200\n",
    "    \n",
    "    midImage[midImage < BLACK_LIMIT] = 0\n",
    "    midImage[midImage > BLACK_LIMIT] = 255\n",
    "\n",
    "    thresh = cv2.threshold(midImage, 190, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    midImage = np.copy(thresh)\n",
    "    \n",
    "#     cv2.imwrite(rotateJpgPath[:-4] + \"_thresh.jpg\", midImage, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])\n",
    "    \n",
    "    dstImage = cv2.Canny(midImage, 80, 200, 3)\n",
    "    \n",
    "#     cv2.imwrite(rotateJpgPath[:-4] + \"_canny.jpg\", dstImage, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])\n",
    "    \n",
    "    lineimage = image.copy()\n",
    " \n",
    "    lines = cv2.HoughLines(dstImage, 1, np.pi/180, 375)\n",
    "    \n",
    "    approvedCount = 0\n",
    "    \n",
    "    verticalCount = 0\n",
    "    verticalSum = 0\n",
    "    \n",
    "    horizontalCount = 0\n",
    "    horizontalSum = 0\n",
    "    \n",
    "    \n",
    "    if lines is None:\n",
    "        print(\"No lines\")\n",
    "        return\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        for rho, theta in lines[i]:\n",
    "            lineAngle = theta / np.pi * 180\n",
    "            \n",
    "            if (lineAngle > 180):\n",
    "                print(lineAngle)\n",
    "                \n",
    "            if (lineAngle < 80 or (lineAngle > 100 and lineAngle < 170) \\\n",
    "                or (lineAngle > 190 and lineAngle < 260) or lineAngle > 280):\n",
    "                continue\n",
    "            else:\n",
    "                horizontalCount += 1\n",
    "                horizontalSum += lineAngle   \n",
    "                \n",
    "                            \n",
    "                a = np.cos(theta)\n",
    "                b = np.sin(theta)\n",
    "                x0 = a * rho\n",
    "                y0 = b * rho\n",
    "                x1 = int(round(x0 + 4000 * (-b)))\n",
    "                y1 = int(round(y0 + 4000 * a))\n",
    "                x2 = int(round(x0 - 4000 * (-b)))\n",
    "                y2 = int(round(y0 - 4000 * a))\n",
    "#                 cv2.line(lineimage, (x1, y1), (x2, y2), (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    average = horizontalSum / horizontalCount - 90 if horizontalCount > 0 else 0\n",
    "    \n",
    "    rotate = lineimage\n",
    "        \n",
    "    h, w = rotate.shape[:2]\n",
    "    RotateMatrix = cv2.getRotationMatrix2D((w/2.0, h/2.0), average, 1)\n",
    "    rotateImg = cv2.warpAffine(rotate, RotateMatrix, (w, h), borderValue=(255, 255, 255))\n",
    "\n",
    "#     cv2.imwrite(rotateJpgPath, rotate, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])\n",
    "    return rotateImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "50705d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def line_intersection(l1, l2):\n",
    "    line1 = ([l1[0],l1[1]],[l1[2],l1[3]])\n",
    "    line2 = ([l2[0],l2[1]],[l2[2],l2[3]])\n",
    "    \n",
    "    xdiff = (line1[0][0] - line1[1][0], line2[0][0] - line2[1][0])\n",
    "    ydiff = (line1[0][1] - line1[1][1], line2[0][1] - line2[1][1])\n",
    "\n",
    "    def det(a, b):\n",
    "        return a[0] * b[1] - a[1] * b[0]\n",
    "\n",
    "    div = det(xdiff, ydiff)\n",
    "    if div == 0:\n",
    "        return None\n",
    "\n",
    "    d = (det(*line1), det(*line2))\n",
    "    x = det(d, xdiff) / div\n",
    "    y = det(d, ydiff) / div\n",
    "    return (int(x), int(y))\n",
    "\n",
    "def distance(point1, point2):\n",
    "    return math.sqrt((point1[0]-point2[0])**2 + (point1[1]-point2[1])**2)\n",
    "\n",
    "def isPontOnLine(point, line):\n",
    "    return abs(distance([line[0],line[1]], point) + distance([line[2],line[3]], point) \\\n",
    "        - distance([line[0],line[1]], [line[2],line[3]])) < 3\n",
    "\n",
    "\n",
    "def getKeyPointsRegions(rotate_img, table_file):\n",
    "    midImage = cv2.cvtColor(rotate_img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "    BLACK_LIMIT = 200\n",
    "    \n",
    "    midImage[midImage < BLACK_LIMIT] = 0\n",
    "    midImage[midImage > BLACK_LIMIT] = 255\n",
    "\n",
    "    thresh = cv2.threshold(midImage, 190, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    horizontal = np.copy(thresh)\n",
    "    vertical = np.copy(thresh)\n",
    "    \n",
    "    scale = 10\n",
    "        \n",
    "    horizontalCols = horizontal.shape[1]\n",
    "    horizontalSize = horizontalCols / scale\n",
    "    horizontalSize = int(horizontalSize)\n",
    "    horizontalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (horizontalSize, 1))\n",
    "    horizontal = cv2.morphologyEx(horizontal, cv2.MORPH_OPEN, horizontalStructure)\n",
    "\n",
    "    \n",
    "    verticalRows = vertical.shape[0]\n",
    "    verticalSize = verticalRows / scale\n",
    "    verticalSize = int(verticalSize)\n",
    "    verticalStructure = cv2.getStructuringElement(cv2.MORPH_RECT, (1, verticalSize))\n",
    "    vertical = cv2.morphologyEx(vertical, cv2.MORPH_OPEN, verticalStructure)\n",
    "    \n",
    "    \n",
    "    SE = cv2.getStructuringElement(cv2.MORPH_RECT, (1,3))\n",
    "    horizontal = cv2.dilate(horizontal, SE, iterations=3)\n",
    "\n",
    "    SE = cv2.getStructuringElement(cv2.MORPH_RECT, (5,1))\n",
    "    vertical = cv2.dilate(vertical, SE, iterations=5)\n",
    "    \n",
    "    lines_mask = horizontal + vertical\n",
    "    \n",
    "    \n",
    "    points_image = rotate_img.copy()\n",
    "    \n",
    "    linesP = cv2.HoughLinesP(lines_mask, 1, np.pi/180, 150, None, 50, 20)\n",
    "    \n",
    "\n",
    "    if linesP is not None:    \n",
    "        horizontalLines = [line[0] for line in linesP if abs(line[0][2] - line[0][0]) > abs(line[0][3] - line[0][1])]\n",
    "        verticalLines = [line[0] for line in linesP if abs(line[0][2] - line[0][0]) < abs(line[0][3] - line[0][1])]\n",
    "        \n",
    "        count = 0\n",
    "        for i in range(0, len(horizontalLines)):\n",
    "            l = horizontalLines[i]\n",
    "            l[0] -= 10\n",
    "            l[2] += 10\n",
    "            horizontalLines[i] = l\n",
    "#             lineimg = cv2.line(points_image, (l[0], l[1]), (l[2], l[3]), (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#             cv2.imwrite(RESULTS_DIR + table_file + str(count) + \"_points.jpg\", lineimg)\n",
    "            count += 1\n",
    "            \n",
    "        for i in range(0, len(verticalLines)):\n",
    "            l = verticalLines[i]\n",
    "            l[1] += 10\n",
    "            l[3] -= 10\n",
    "            verticalLines[i] = l\n",
    "#             lineimg = cv2.line(points_image, (l[0], l[1]), (l[2], l[3]), (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#             cv2.imwrite(RESULTS_DIR + table_file + str(count) + \"_points.jpg\", lineimg)\n",
    "            count += 1\n",
    "            \n",
    "#         print(count)\n",
    "        keypoints = []\n",
    "        count = 0\n",
    "        for horizontal_line in horizontalLines:\n",
    "            for vertical_line in verticalLines:\n",
    "                point = line_intersection(horizontal_line, vertical_line)\n",
    "                if point is not None:\n",
    "                    if isPontOnLine(point, vertical_line) and isPontOnLine(point, horizontal_line):\n",
    "                        keypoints.append(point)\n",
    "                    \n",
    "        hasChanges = True\n",
    "        while hasChanges:\n",
    "            hasChanges = False\n",
    "            \n",
    "            for keypoint in keypoints:\n",
    "                if hasChanges:\n",
    "                    break\n",
    "                neighbours = []\n",
    "                for neighbour in keypoints:\n",
    "                    if keypoint == neighbour:\n",
    "                        continue\n",
    "                        \n",
    "                    if math.sqrt((keypoint[0]-neighbour[0])**2 + (keypoint[1]-neighbour[1])**2) < 30:\n",
    "                        neighbours.append(neighbour)\n",
    "\n",
    "                if len(neighbours) > 0:\n",
    "                    new_keypoint = keypoint\n",
    "                    for neighbour in neighbours:\n",
    "                        new_keypoint = (new_keypoint[0] + neighbour[0], \n",
    "                                        new_keypoint[1] + neighbour[1])\n",
    "                    \n",
    "                    new_keypoint = (int(new_keypoint[0] / (len(neighbours) + 1)), \n",
    "                                    int(new_keypoint[1] / (len(neighbours) + 1)))\n",
    "\n",
    "                    keypoints = [point for point in keypoints if point not in neighbours and point != keypoint]\n",
    "                    keypoints.append(new_keypoint)\n",
    "                    \n",
    "                    hasChanges = True\n",
    "                    break\n",
    "                        \n",
    "        for point in keypoints:\n",
    "            cv2.circle(points_image, point, radius=10, color=(0, 255, 0), thickness=-1)\n",
    "                    \n",
    "#         cv2.imwrite(RESULTS_DIR + table_file + \"_points.jpg\", points_image)\n",
    "        \n",
    "        return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e1a0f6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33_131-110-1010-001_1.jpg\n",
      "61 0\n",
      "Not enough elements\n",
      "33_311-1021-001_1.jpg\n",
      "61 65\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_311-1022-001_1.jpg\n",
      "61 63\n",
      "Matches: 60\n",
      "Correct pattern!\n",
      "33_311-1821-001_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/titrom/miniconda3/envs/keyValEnv/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in int_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 79\n",
      "Matches: 36\n",
      "Another pattern!\n",
      "33_641-1000-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1001-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1010-001_1.jpg\n",
      "61 64\n",
      "Matches: 56\n",
      "Correct pattern!\n",
      "33_641-1020-001_1.jpg\n",
      "61 69\n",
      "Matches: 48\n",
      "Another pattern!\n",
      "33_641-1021-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1023-001_1.jpg\n",
      "61 62\n",
      "Matches: 59\n",
      "Correct pattern!\n",
      "33_641-1024-001_1.jpg\n",
      "33_641-1040-001_1.jpg\n",
      "61 75\n",
      "Matches: 28\n",
      "Another pattern!\n",
      "33_641-1041-001_1.jpg\n",
      "61 55\n",
      "Matches: 51\n",
      "Correct pattern!\n",
      "33_641-1042-001_1.jpg\n",
      "61 63\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1048-001_1.jpg\n",
      "61 61\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1049-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1050-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1060-001_1.jpg\n",
      "61 63\n",
      "Matches: 60\n",
      "Correct pattern!\n",
      "33_641-1061-001_1.jpg\n",
      "61 56\n",
      "Matches: 54\n",
      "Correct pattern!\n",
      "33_641-1062-001_1.jpg\n",
      "61 63\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-10SK1-001_1.jpg\n",
      "61 0\n",
      "Not enough elements\n",
      "33_641-130-1090-001_1.jpg\n",
      "61 63\n",
      "Matches: 60\n",
      "Correct pattern!\n",
      "33_641-130-1091-001_1.jpg\n",
      "61 62\n",
      "Matches: 60\n",
      "Correct pattern!\n",
      "33_641-130-1092-001_1.jpg\n",
      "61 0\n",
      "Not enough elements\n",
      "33_641-1501-001_1.jpg\n",
      "61 53\n",
      "Matches: 51\n",
      "Correct pattern!\n",
      "33_641-1502-001_1.jpg\n",
      "61 64\n",
      "Matches: 58\n",
      "Correct pattern!\n",
      "33_641-1505-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1506-001_1.jpg\n",
      "61 65\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1507-001_1.jpg\n",
      "61 63\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1509-001_1.jpg\n",
      "61 67\n",
      "Matches: 40\n",
      "Another pattern!\n",
      "33_641-1511-001_1.jpg\n",
      "61 61\n",
      "Matches: 59\n",
      "Correct pattern!\n",
      "33_641-1512-001_1.jpg\n",
      "61 61\n",
      "Matches: 57\n",
      "Correct pattern!\n",
      "33_641-1513-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1514-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1515-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1516-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1520-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1525-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-1528-001_1.jpg\n",
      "61 62\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-2046-016_1.jpg\n",
      "61 64\n",
      "Matches: 57\n",
      "Correct pattern!\n",
      "33_641-2070-001_1.jpg\n",
      "61 60\n",
      "Matches: 57\n",
      "Correct pattern!\n",
      "33_641-2070-002_1.jpg\n",
      "61 52\n",
      "Matches: 51\n",
      "Correct pattern!\n",
      "33_641-2070-003_1.jpg\n",
      "61 63\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-2070-004_1.jpg\n",
      "61 98\n",
      "Matches: 56\n",
      "Another pattern!\n",
      "33_641-2090-001_1.jpg\n",
      "61 60\n",
      "Matches: 59\n",
      "Correct pattern!\n",
      "33_641-2090-002_1.jpg\n",
      "61 61\n",
      "Matches: 60\n",
      "Correct pattern!\n",
      "33_641-2090-003_1.jpg\n",
      "61 63\n",
      "Matches: 61\n",
      "Correct pattern!\n",
      "33_641-2130-005_1.jpg\n",
      "61 61\n",
      "Matches: 59\n",
      "Correct pattern!\n"
     ]
    }
   ],
   "source": [
    "createDir(RESULTS_DIR, '.jpg')\n",
    "PATTERN_NAME = \"pattern_3.jpg\"\n",
    "# PATTERN_NAME = \"form.jpg\"\n",
    "  \n",
    "pattern_im = cv2.imread(PATTERN_NAME, cv2.IMREAD_COLOR)\n",
    "rotatePatternPath = RESULTS_DIR + PATTERN_NAME[:-4] + \"_r.jpg\"\n",
    "rotate_pattern = rotateIMG(pattern_im)\n",
    "cv2.imwrite(rotatePatternPath, rotate_pattern)\n",
    "regions_pattern = getKeyPointsRegions(rotate_pattern, PATTERN_NAME)\n",
    "    \n",
    "RATION_TRESH = 0.7\n",
    "for table_file in get_files(\"tables/\", \".jpg\"):\n",
    "\n",
    "#     if table_file != \"33_311-1021-001_1.jpg\":\n",
    "#         continue\n",
    "    \n",
    "    print(table_file)\n",
    "    \n",
    "    table_path = \"tables/\" + table_file\n",
    "    rotateJpgPath = RESULTS_DIR + table_file[:-4] + \"_r.jpg\"\n",
    "\n",
    "    table_im = cv2.imread(table_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    rotate_table = rotateIMG(table_im)\n",
    "    regions_table = getKeyPointsRegions(rotate_table, table_file)\n",
    "    \n",
    "    if regions_table is not None:\n",
    "        alignImages(table_path.split(\"/\")[-1].split(\".\")[0], rotate_pattern.copy(), rotate_table.copy(), \n",
    "                    regions_pattern.copy(), regions_table.copy())\n",
    "\n",
    "#     align(table_path.split(\"/\")[-1].split(\".\")[0], pattern_im, table_im)\n",
    "#     match(table_path.split(\"/\")[-1].split(\".\")[0], pattern_im, table_im)\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea7b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e271a36-18dc-4a77-a51b-3de93988b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add middle of vertices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
